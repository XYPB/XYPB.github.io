<!DOCTYPE html>
<html>
<head>
    <title>Yuexi Du</title>

    <!-- Meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <!-- Bootstrap CSS -->
    <link href="assets/css/bootstrap.min.css" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
    
    <!-- Google Fonts -->
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;700&display=swap" rel="stylesheet">

    <!-- Custom Styles -->
    <style>
          body {
            font-family: 'Roboto', sans-serif;
            font-size: 16px;
            background-color: #f8f9fa;
            color: #333;
            line-height: 1.6;
          }
          a {
            color: #0066cc;
            transition: color 0.2s;
          }
          a:hover {
            color: #004499;
            text-decoration: none;
          }
          #header {
            background: linear-gradient(135deg, #eef2f3 0%, #8e9eab 100%);
            padding: 80px 0;
            margin-bottom: 40px;
            box-shadow: 0 4px 6px rgba(0,0,0,0.1);
          }
          #header .container {
            text-align: center;
          }
          #footer {
            background-color: #f8f9fa;
            padding: 40px;
            text-align: center;
            color: #777;
            font-size: 0.9rem;
          }
          #header-text-name {
            font-size: 3rem;
            font-weight: 700;
            color: #2c3e50;
            margin-bottom: 10px;
          }
          #header-text-email {
            font-size: 1.2rem;
            font-weight: 300;
            color: #555;
            margin-bottom: 20px;
          }
          #header a {
            margin: 0 10px;
            font-weight: 500;
            color: #444;
          }
          #header a:hover {
            color: #000;
          }
          
          /* Main Content Container */
          body > .container {
            background-color: #ffffff;
            padding: 40px;
            border-radius: 8px;
            box-shadow: 0 2px 15px rgba(0,0,0,0.05);
            margin-bottom: 40px;
            max-width: 1000px;
          }

          h1 {
            font-size: 1.8rem;
            font-weight: 700;
            color: #2c3e50;
            border-bottom: 2px solid #eee;
            padding-bottom: 10px;
            margin-bottom: 25px;
            margin-top: 10px;
          }
          
          p {
            text-align: justify;
            margin-bottom: 1.2rem;
          }

          .vspace-top {
            margin-top: 40px;
          }
          .vspace-top-news {
              margin-top: 0;
              padding: 12px 0;
              border-bottom: 1px solid #f0f0f0;
          }
          .vspace-top-news:last-child {
              border-bottom: none;
          }
          .news-container {
              height: 300px;
              overflow-y: auto;
              border: 1px solid #eee;
              padding: 0 15px;
              border-radius: 4px;
              background-color: #fcfcfc;
              margin-top: 15px;
          }
          .paper-image {
            width: 100%;
            border-radius: 4px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
            border: 1px solid #eee;
            transition: transform 0.2s;
          }
          .paper-image:hover {
            transform: scale(1.02);
          }
          .news-date {
              font-weight: bold;
              color: #555;
              font-size: 0.95rem;
          }
          .course-number {
              font-weight: bold;
              color: #444;
          }
          .paper-title {
            font-weight: 700;
            font-size: 1.1rem;
            color: #222;
          }
          .paper-authors {
            font-style: italic;
            color: #555;
            margin-bottom: 5px;
          }
          .paper-desc {
             color: #666;
             margin-bottom: 5px;
          }
          .company-name {
            font-weight: bold;
            font-size: 1.1rem;
          }
          .intern-host {
            font-style: italic;
            color: #666;
            margin-bottom: 5px;
          }
    </style>
</head>

<body>
    <div id='header'>
        <div class='container'>
            <div class='row'>
                <!---
                <div class="col-sm-3 offset-sm-1">
                    <img src='imgs/portrait.jpeg' class='img-fluid' id='portrait'>
                </div>
                -->
                
                <div class="col">
                    <div id='header-text-name'>
                        Yuexi Du
                    </div>
                    <div id='header-text-email'>
                    <i class="fa fa-envelope" aria-hidden="true"></i> yuexi.du@yale.edu
                  </div>
                  <div>
                    <a href="https://github.com/XYPB"><i class="fa fa-github" aria-hidden="true"></i> GitHub</a>
                    <a href="https://scholar.google.com/citations?user=qQWCY4UAAAAJ&hl=en"><i class="fa fa-graduation-cap" aria-hidden="true"></i> Google Scholar</a>
                    <a href="https://twitter.com/yuexi_du"><i class="fa fa-linkedin" aria-hidden="true"></i> Twitter</a>
                    <a href="linkedin.com/in/yuexi-du-42b972208"><i class="fa fa-twitter" aria-hidden="true"></i> Linkedin</a>
                    <a href="resume/resume_Yuexi_Du.pdf"><i class="fa fa-file-pdf-o" aria-hidden="true"></i> Download CV</a> 
                  </div>
                </div>
            </div>
        </div>
    </div>

    <div class='container'>
        <div class='row vspace-top'>
            <div class='col-12'>
                <h1>Bio</h1>
                <p>
                    I am a fourth-year Ph.D. candidate at Yale University, majoring in BME, advised by Prof. <a href="https://www.hellonicha.com/">Nicha C. Dvornek</a>. I am also actively collaborating with Prof. <a href="https://scholar.google.com/citations?user=ccSuHj8AAAAJ&hl=en">John Onofrey</a>. Before that, I got my Bachelor's degree in CS at the University of Michigan, Ann Arbor, advised by Prof. <a href="https://andrewowens.com/">Andrew Owens</a>, and another Bachelor's degree in ECE at Shanghai Jiao Tong University.
                </p>
                <p>
                    My research interest lies in the computer vision, multi-modality learning, and medical image analysis. I am always thrilled to work on questions that address real-world needs.
                </p>
                <p>
                    I am also honored to serve as a reviewer in conferences and journals, including CVPR, ICCV, ECCV, NeurIPS, AAAI, MICCAI, ISBI, ICLR, AISTATS, IJCAI, ICML, and IEEE-TMM, IJCV, IEEE-TPAMI, MedIA.
                </p>

                <!-- - List of news  -->
                <div class='vspace-top'>
                    <h1>News</h1>
                </div>

                <div class="news-container">
                <div class='row vspace-top-news'>
                    <div class="col-sm-2 news-date">
                        Nov 2025
                    </div>
                    <div class="col">
                        I will join Google during the next summer as an Intern working with Dr. Yan Xu!
                    </div>
                </div>

                <div class='row vspace-top-news'>
                    <div class="col-sm-2 news-date">
                        June 2025
                    </div>
                    <div class="col">
                        One first-author paper "Geometry-Guided Local Alignment for Multi-View Visual Language Pre-Training in Mammography" got accepted by <b>MICCAI 2025</b>ðŸŽ‰! See you at Daejeon~
                    </div>
                </div>

                <div class='row vspace-top-news'>
                    <div class="col-sm-2 news-date">
                        June 2025
                    </div>
                    <div class="col">
                        I have joined MSRA for summer research internship, mentored by Dr. Jinglu Wang!
                    </div>
                </div>

                <div class='row vspace-top-news'>
                    <div class="col-sm-2 news-date">
                        May 2025
                    </div>
                    <div class="col">
                        Our paper "MaMA" was awarded with <element  style="color:crimson">Best Oral Paper Runner-up</element> (ranked #2) at <b>IPMI 2025</b>ðŸŽ‰! Huge honor to recieve this!
                    </div>
                </div>

                <div class='row vspace-top-news'>
                    <div class="col-sm-2 news-date">
                        Feb 2025
                    </div>
                    <div class="col">
                        Our paper "MaMA: Multi-View and Multi-Scale Alignment for Contrastive Language-Image Pre-training in Mammography" was accepted by <b>IPMI 2025</b>ðŸŽ‰ for <element  style="color:crimson">Oral Presentation</element>! See you in Greece (again)!
                    </div>
                </div>
                
                <div class='row vspace-top-news'>
                    <div class="col-sm-2 news-date">
                        Jan 2025
                    </div>
                    <div class="col">
                        Two papers about rotational equivarient convolution kernel accepted by <b>ISBI 2025</b>! See you in Houston!
                    </div>
                </div>
                
                <div class='row vspace-top-news'>
                    <div class="col-sm-2 news-date">
                        Nov 2024
                    </div>
                    <div class="col">
                        I have just passed my area exam and officially become a Ph.D. candidate!ðŸŽ‰
                    </div>
                </div>
                
                <div class='row vspace-top-news'>
                    <div class="col-sm-2 news-date">
                        Oct 2024
                    </div>
                    <div class="col">
                        I am honored to receive the $800 Yale University Conference Travel Funding! 
                    </div>
                </div>
                
                <div class='row vspace-top-news'>
                    <div class="col-sm-2 news-date">
                        Sept 2024
                    </div>
                    <div class="col">
                        ðŸŽŠWe just won the <b>first place (#1)</b> in the <a href="https://bionlplab.github.io/2024_MICCAI_CXRLT/">MICCAI 2024 CXR-LT Challenge</a> for the task of <i>Long-tail Classification on gold standard test set</i>! We were also recognized as the <b>overall best-performing team</b> and win a prize of $900! Really appreciate my collaborators!
                    </div>
                </div>

                <div class='row vspace-top-news'>
                    <div class="col-sm-2 news-date">
                        Jun 2024
                    </div>
                    <div class="col">
                        One first-author paper <i>"CLEFT: Language-Image Contrastive Learning with Efficient Large Language Model and Prompt Fine-Tuning"</i> is accepted by <b>MICCAI 2024</b>! I will be presenting this paper in person at Marrakesh!
                    </div>
                </div>

                <div class='row vspace-top-news'>
                    <div class="col-sm-2 news-date">
                        Feb 2024
                    </div>
                    <div class="col">
                        One first-author paper <i>"SIFT-DBT: Self-supervised Initialization and Fine-Tuning for Imbalanced Digital Breast Tomosynthesis Image Classification"</i> and one another paper accepted by <b>ISBI 2024</b>! See you in Athens!
                    </div>
                </div>
                
                <div class='row vspace-top-news'>
                    <div class="col-sm-2 news-date">
                        Jun 2023
                    </div>
                    <div class="col">
                        I'll join <b>Nicha's</b> Group as a Ph.D. student next semester and work on DBT data and Breast cancer.
                    </div>
                </div>

                <div class='row vspace-top-news'>
                    <div class="col-sm-2 news-date">
                        Feb 2023
                    </div>
                    <div class="col">
                        Our new work <i>"Conditional Generation of Audio from Video via Foley Analogies"</i> with Andrew has been accepted by <b>CVPR 2023</b>!
                    </div>
                </div>

                <div class='row vspace-top-news'>
                    <div class="col-sm-2 news-date">
                        Jan 2023
                    </div>
                    <div class="col">
                        Our work <i>"RetCCL: Clustering-guided contrastive learning for whole-slide image retrieval"</i> is now available on <b><i>Medical Image Analysis</i></b> (IF=<b>10.9</b>)!
                    </div>
                </div>

                <div class='row vspace-top-news'>
                    <div class="col-sm-2 news-date">
                        Jan 2023
                    </div>
                    <div class="col">
                        I will rotate at <b>Prof. John Onofrey's</b> lab this semester and working on rotational invariant feature extractor!
                    </div>
                </div>

                <div class='row vspace-top-news'>
                    <div class="col-sm-2 news-date">
                        Sept 2022
                    </div>
                    <div class="col">
                        I will join Yale University as a Ph.D. student majoring in BME!
                    </div>
                </div>
                </div>
                <div>&nbsp;</div>

                <div class='vspace-top'>
                    <h1>Work Experience</h1>
                </div>

                
                <div class='row vspace-top'>
                    <div class="col-sm-2">
                        <img width="90%" src="assets/logos/ms_logo.png" style="border-radius: 4px;">
                        </img>
                    </div>
                
                    <div class="col-sm-10">
                        <div class='company-name'>
                            Microsoft Research Asia - Media Computing Group
                        </div>
                        <div class='intern-host'>
                            Dr. Jinglu Wang
                        </div>
                        <div>
                            Research Intern. Work on visual evidence grounded medical VQA agent based on RLVR.
                        </div>
                    </div>
                </div>

                <div class='row vspace-top'>
                    <div class="col-sm-2">
                        <img width="90%" src="assets/logos/tencent_ailab.png" style="border-radius: 4px;">
                        </img>
                    </div>
                
                    <div class="col-sm-10">
                        <div class='company-name'>
                            Tencent AI Lab - AI Healthcare Group
                        </div>
                        <div class='intern-host'>
                            Dr. Xiao Han, M.Sc Sen Yang
                        </div>
                        <div>
                            Algorithm R&D Intern. Work on pathological image selfsupervised representation learning and fast Whole-Slide Image(WSI) search system.
                        </div>
                    </div>
                </div>
                
                <div>&nbsp;</div>

                <div class='vspace-top'>
                    <h1>Selected Publications</h1>
                </div>

                <!--- List of publications --->

                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <img class="paper-image" src="assets/images/glam.png">
                        </img>
                    </div>
                
                    <div class="col-sm-9">
                        <div>&nbsp;</div>
                        <div class='paper-title'>
                            GLAM: Geometry-Guided Local Alignment for Multi-View Visual Language Pre-Training in Mammography
                        </div>
                        <div class='paper-desc'>
                            MICCAI 2025
                        </div>
                        <div class='paper-authors'>
                            <b>Yuexi Du</b>, Lihui Chen, <a href="https://www.hellonicha.com/">Nicha C. Dvornek</a>
                        </div>
                        <div>
                            <a href="https://arxiv.org/abs/2509.10344">[arXiv]</a>
                            <a href="https://github.com/XYPB/GLAM">[Github]</a>
                            <a href="cites/glam.txt">[Bibtex]</a>
                        </div>
                    </div>
                </div>

                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <img class="paper-image" src="assets/images/MaMA.png">
                        </img>
                    </div>
                
                    <div class="col-sm-9">
                        <div>&nbsp;</div>
                        <div class='paper-title'>
                            MaMA: Multi-View and Multi-Scale Alignment for Contrastive Language-Image Pre-training in Mammography
                        </div>
                        <div class='paper-desc'>
                            IPMI 2025 <element  style="color:crimson">Oral, Best Oral Paper Runner-up</element> (basis of the best solution of the MICCAI 24 CXR-LT Challenge)
                        </div>
                        <div class='paper-authors'>
                            <b>Yuexi Du</b>, <a href="https://medicine.yale.edu/profile/john-onofrey/">John Onofrey</a>, <a href="https://www.hellonicha.com/">Nicha C. Dvornek</a>
                        </div>
                        <div>
                            <a href="https://arxiv.org/abs/2409.18119">[arXiv]</a>
                            <a href="https://github.com/XYPB/MaMA">[Github]</a>
                            <a href="cites/mama.txt">[Bibtex]</a>
                        </div>
                    </div>
                </div>

                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <img class="paper-image" src="assets/images/sre_conv.gif">
                        </img>
                    </div>
                
                    <div class="col-sm-9">
                        <div>&nbsp;</div>
                        <div class='paper-title'>
                            SRE-Conv: Symmetric Rotation Equivariant Convolution for Biomedical Image Classification
                        </div>
                        <div class='paper-desc'>
                            IEEE ISBI 2025
                        </div>
                        <div class='paper-authors'>
                            <b>Yuexi Du</b>, Jiazhen Zhang, <a href="https://medicine.yale.edu/profile/tal-zeevi/">Tal Zeevi</a>, <a href="https://www.hellonicha.com/">Nicha C. Dvornek</a>, <a href="https://medicine.yale.edu/profile/john-onofrey/">John Onofrey</a>
                        </div>
                        <div>
                            <a href="https://arxiv.org/abs/2501.09753">[Paper]</a>
                            <a href="https://github.com/XYPB/SRE-Conv">[Github]</a>
                            <a href="cites/sre-conv.txt">[Bibtex]</a>
                        </div>
                    </div>
                </div>

                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <img class="paper-image" src="assets/images/cleft.png">
                        </img>
                    </div>
                
                    <div class="col-sm-9">
                        <div>&nbsp;</div>
                        <div class='paper-title'>
                            CLEFT: Language-Image Contrastive Learning with Efficient Large Language Model and Prompt Fine-Tuning
                        </div>
                        <div class='paper-desc'>
                            MICCAI 2024
                        </div>
                        <div class='paper-authors'>
                            <b>Yuexi Du</b>, Brian Chang, <a href="https://www.hellonicha.com/">Nicha C. Dvornek</a>
                        </div>
                        <div>
                            <a href="https://arxiv.org/abs/2407.21011">[Paper]</a>
                            <a href="https://github.com/XYPB/CLEFT">[Github]</a>
                            <a href="cites/cleft.txt">[Bibtex]</a>
                        </div>
                    </div>
                </div>

                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <img class="paper-image" src="assets/images/volume_all_roc.png">
                        </img>
                    </div>
                
                    <div class="col-sm-9">
                        <div>&nbsp;</div>
                        <div class='paper-title'>
                            SIFT-DBT: Self-supervised Initialization and Fine-Tuning for Imbalanced Digital Breast Tomosynthesis Image Classification
                        </div>
                        <div class='paper-desc'>
                            IEEE ISBI 2024
                        </div>
                        <div class='paper-authors'>
                            <b>Yuexi Du</b>, Regina J Hooley, John Lewin, <a href="https://www.hellonicha.com/">Nicha C. Dvornek</a>
                        </div>
                        <div>
                            <a href="https://arxiv.org/pdf/2403.13148">[Paper]</a>
                            <a href="https://github.com/XYPB/SIFT_DBT">[Github]</a>
                            <a href="assets/pdfs/sift_dbt2024_poster.pdf">[Poster]</a>
                            <a href="cites/sift-dbt.txt">[Bibtex]</a>
                        </div>
                    </div>
                </div>

                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <img class="paper-image" src="assets/images/avanalogies.png">
                        </img>
                    </div>
                
                    <div class="col-sm-9">
                        <div>&nbsp;</div>
                        <div class='paper-title'>
                            Conditional Generation of Audio from Video via Foley Analogies
                        </div>
                        <div class='paper-desc'>
                            CVPR 2023
                        </div>
                        <div class='paper-authors'>
                            <b>Yuexi Du</b>, <a href="https://ificl.github.io/">Ziyang Chen</a>, <a href="https://www.justinsalamon.com/">Justin Salamon</a>, <a href="https://bryanrussell.org/">Bryan Russell</a>, <a href="https://andrewowens.com/">Andrew Owens</a>
                        </div>
                        <div>
                            <a href="https://xypb.github.io/CondFoleyGen/">[Project page]</a>
                            <a href="https://arxiv.org/abs/2304.08490">[Paper]</a>
                            <a href="https://github.com/XYPB/CondFoleyGen">[Github]</a>
                            <a href="cites/condfoleygen.txt">[Bibtex]</a>
                        </div>
                    </div>
                </div>

                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <img class="paper-image" src="assets/images/retccl.png">
                        </img>
                    </div>
                
                    <div class="col-sm-9">
                        <!-- <div>&nbsp;</div> -->
                        <div class='paper-title'>
                            RetCCL: Clustering-guided contrastive learning for whole-slide image retrieval
                        </div>
                        <div class='paper-desc'>
                            Medical Image Analysis (IF=<b>10.9</b>)
                        </div>
                        <div class='paper-authors'>
                            Xiyue Wang, <b>Yuexi Du</b>, Sen Yang, Jun Zhang, Minghui Wang, Jing Zhang, Wei Yang, Junzhou Huang, Xiao Han
                        </div>
                        <div>
                            <a href="https://www.sciencedirect.com/science/article/pii/S1361841522002730">[Paper]</a>
                            <a href="https://github.com/Xiyue-Wang/RetCCL">[Github]</a>
                            <a href="cites/retccl.txt">[Bibtex]</a>
                        </div>
                    </div>
                </div>
                <div>&nbsp;</div>

                <div class='vspace-top'>
                    <h1>Selected Projects</h1>
                </div>

                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <img class="paper-image" src="assets/images/DDM2.png">
                        </img>
                    </div>
                
                    <div class="col-sm-9">
                        <div>&nbsp;</div>
                        <div class='paper-title'>
                            Controlled and Self-supervised Diffusion MRI Denoising via Generative Diffusion
                        </div>
                        <div class='paper-desc'>
                            CPSC 586 Probabilistic Machine Learning Final Project
                        </div>
                        <div class='paper-authors'>
                            <b>Yuexi Du</b>
                        </div>
                        <div>
                            <a href="https://drive.google.com/file/d/1iYNVbocsrPnjHuh0RqnwLCIvb7VLpEwE/view?usp=sharing">[Report]</a>
                            <a href="https://github.com/XYPB/DDM2">[Github]</a>
                        </div>
                    </div>
                </div>

                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <img class="paper-image" src="assets/images/colorVAE.jpg">
                        </img>
                    </div>
                
                    <div class="col-sm-9">
                        <div>&nbsp;</div>
                        <div>&nbsp;</div>
                        <div class='paper-title'>
                            COLOR-VAE: Generative Colorization with Variational Auto-encoder
                        </div>
                        <div class='paper-desc'>
                            EECS 442 Computer Vision Final Project (Rank <b>#1</b>)
                        </div>
                        <div class='paper-authors'>
                            <b>Yuexi Du</b>, Muchen Xu, Yuang Zhang, Zhanhui Zhou, Chenshu Zhu
                        </div>
                        <div>
                            <a href="https://drive.google.com/file/d/1NyOGlJl9AJlpn2WZPQXuo36-uacNff3Y/view">[Report]</a>
                            <a href="https://github.com/XYPB/ColorVAE">[Github]</a>
                            <a href="https://drive.google.com/file/d/1HQzCaNgMwJ8CPR0Vxa9Zt1a_jjqoBpHX/view">[Video]</a>
                        </div>
                    </div>
                </div>

                

                <div>&nbsp;</div>

                <div class='vspace-top'>
                    <h1>Teaching</h1>
                </div>

                <div class='row'>
                    <div class="col-sm-2 course-number">
                        ENAS 912
                    </div>
                    <div class="col">
                        Biomedical Image Processing and Analysis. Teaching Fellow. Winter 2023 at Yale. With <a href="https://medicine.yale.edu/profile/james-duncan/">James Duncan</a> and <a href="https://medicine.yale.edu/profile/lawrence-staib/">Lawrence Staib</a>
                    </div>
                </div>
                <div class='row'>
                    <div class="col-sm-2 course-number">
                        EECS 442 
                    </div>
                    <div class="col">
                        Computer Vision. Instructor aide. Spring 2022 at UM. With <a href="https://web.eecs.umich.edu/~fouhey/">David Fouhey</a>
                    </div>
                </div>
                <div class='row'>
                    <div class="col-sm-2 course-number">
                        VR 246
                    </div>
                    <div class="col">
                        Introduction to Comics & Visual Art. Teaching Assistant. Spring 2021 at SJTU UMJI. With Jeolle Tybon
                    </div>
                </div>
                <div class='row'>
                    <div class="col-sm-2 course-number">
                        VE 101
                    </div>
                    <div class="col">
                        Introduction to Computer & Programming. Teaching Assistant. Winter 2020 at SJTU UMJI. With <a href="https://umji.sjtu.edu.cn/~jgwu/">Jigang Wu</a>
                    </div>
                </div>
            </div>
        </div>
    </div>


    <div id='footer' class='vspace-top'>
        <div class="container">
            &copy; 2025 Yuexi Du.
        </div>
    </div>

    <!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>
    <!-- Include all compiled plugins (below), or include individual files as needed -->
    <script src="js/bootstrap.min.js"></script>
</body>
</html>
